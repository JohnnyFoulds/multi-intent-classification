{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-01 : Basic Classification Test\n",
    "\n",
    "Test the basic functionality for using a Mistral Model for classifying customer reviews with multiple intents.\n",
    "\n",
    "## Ollama\n",
    "\n",
    "To keep things simple the 7B model released by Mistral AI, updated to version 0.2 will be used and hosted locally on the same machine with Ollama. In a production situation this model can be hosted in [AWS SageMaker](https://aws.amazon.com/blogs/machine-learning/mistral-7b-foundation-models-from-mistral-ai-are-now-available-in-amazon-sagemaker-jumpstart/) or a hosted service as provided by [Mistral AI](https://docs.mistral.ai/). \n",
    "\n",
    "Linux users can install Ollama with the following command:\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "The following commands are then executed to run Mistral:\n",
    "\n",
    "```bash\n",
    "ollama pull mistral\n",
    "ollama run mistral\n",
    "```\n",
    "\n",
    "The following command can be executed to confirm that the model is running as expected:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:11434/api/generate -d '{\n",
    "  \"model\": \"mistral\",\n",
    "  \"prompt\":\"Here is a story about llamas eating grass\"\n",
    " }'\n",
    "```\n",
    "\n",
    "## References\n",
    "\n",
    "- [Get up and running with large language models, locally](https://ollama.com/)\n",
    "- [Mistral with Ollama](https://ollama.com/library/mistral)\n",
    "- [LangChain Ollama](https://python.langchain.com/docs/integrations/llms/ollama#via-langchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LLM \n",
    "\n",
    "Create the LangChain client to use the Mistral model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " I'm an assistant designed to help answer questions and generate text based on given prompts. I don't have the ability to hold beliefs or make statements as if I were NASA. However, I can tell you that NASA has never made such a statement about the moon being a large cheese in the sky. The moon is actually a terrestrial planet, not a dairy product."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the client\n",
    "llm = Ollama(\n",
    "    model=\"mistral\",\n",
    "    top_p=0.001,\n",
    "    temperature=0.001,\n",
    "    num_predict=512)\n",
    "\n",
    "# ensure that the client is working\n",
    "Markdown(\n",
    "    llm.invoke(\"NASA said the moon is just a large cheese in the sky! ðŸ§€\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Classification\n",
    "\n",
    "The `service.classification.classification` module provides an abstraction the retrieve classifications from a user review.\n",
    "\n",
    "- The possible categories (intents) are configured in `src/config/category_definitions.jsonl`\n",
    "\n",
    "- Multiple prompts, similar to a Chain-of-Thought (CoT) approach is used to categorize reviews.\n",
    "  1. First a general plan of action is composed to categorize the review via `src/config/planning_prompt.txt`.\n",
    "  2. Next only the main categories are identified: `src/config/identification_prompt.txt`.\n",
    "  3. Finally structured output is produced identifying the multiple intents and sentiments as shown in the code sample below: `src/config/sentiment_prompt.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import service.classification as classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [{'category': 'Network Coverage',\n",
      "                 'reason': \"The text mentions 'bad network service' which \"\n",
      "                           'falls under the Network Coverage category.',\n",
      "                 'relevance': 1.0,\n",
      "                 'sentiment': 'negative'}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"The quick brown fox is experiencing bad network service. However, the lazy dog has fast internet.\"\n",
    "result = classification.get_classification(text=text, llm=llm)\n",
    "\n",
    "pprint(result.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'categories': [{'category': 'Billing',\n",
      "                 'reason': \"The text mentions 'over billing mistakes' by MTN.\",\n",
      "                 'relevance': 1.0,\n",
      "                 'sentiment': 'negative'},\n",
      "                {'category': \"Customer's Feeling\",\n",
      "                 'reason': \"The text expresses the customer's negative emotion \"\n",
      "                           'towards MTN.',\n",
      "                 'relevance': 1.0,\n",
      "                 'sentiment': 'negative'}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"MTN really rubs my tits the wrong way with their over billing mistakes.\"\n",
    "result = classification.get_classification(text=text, llm=llm)\n",
    "\n",
    "pprint(result.dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
